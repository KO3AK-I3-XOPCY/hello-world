Running: /usr/lib/jvm/java-1.8.0-openjdk-amd64/bin/java -client -Ddaemon.name= -Dstorm.options= -Dstorm.home=/usr/local/apache-storm-1.0.6 -Dstorm.log.dir=/usr/local/apache-storm-1.0.6/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /usr/local/apache-storm-1.0.6/lib/disruptor-3.3.2.jar:/usr/local/apache-storm-1.0.6/lib/storm-rename-hack-1.0.6.jar:/usr/local/apache-storm-1.0.6/lib/servlet-api-2.5.jar:/usr/local/apache-storm-1.0.6/lib/reflectasm-1.10.1.jar:/usr/local/apache-storm-1.0.6/lib/log4j-over-slf4j-1.6.6.jar:/usr/local/apache-storm-1.0.6/lib/objenesis-2.1.jar:/usr/local/apache-storm-1.0.6/lib/asm-5.0.3.jar:/usr/local/apache-storm-1.0.6/lib/log4j-api-2.8.jar:/usr/local/apache-storm-1.0.6/lib/log4j-core-2.8.jar:/usr/local/apache-storm-1.0.6/lib/slf4j-api-1.7.21.jar:/usr/local/apache-storm-1.0.6/lib/kryo-3.0.3.jar:/usr/local/apache-storm-1.0.6/lib/storm-core-1.0.6.jar:/usr/local/apache-storm-1.0.6/lib/minlog-1.3.0.jar:/usr/local/apache-storm-1.0.6/lib/log4j-slf4j-impl-2.8.jar:/usr/local/apache-storm-1.0.6/lib/clojure-1.7.0.jar:target/storm-example-0.0.1-SNAPSHOT.jar:/usr/local/storm/conf:/usr/local/apache-storm-1.0.6/bin -Dstorm.jar=target/storm-example-0.0.1-SNAPSHOT.jar TopWordFinderTopologyPartB
3276 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
3279 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:host.name=e59e53cc954f
3288 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.version=1.8.0_162
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.vendor=Oracle Corporation
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.class.path=/usr/local/apache-storm-1.0.6/lib/disruptor-3.3.2.jar:/usr/local/apache-storm-1.0.6/lib/storm-rename-hack-1.0.6.jar:/usr/local/apache-storm-1.0.6/lib/servlet-api-2.5.jar:/usr/local/apache-storm-1.0.6/lib/reflectasm-1.10.1.jar:/usr/local/apache-storm-1.0.6/lib/log4j-over-slf4j-1.6.6.jar:/usr/local/apache-storm-1.0.6/lib/objenesis-2.1.jar:/usr/local/apache-storm-1.0.6/lib/asm-5.0.3.jar:/usr/local/apache-storm-1.0.6/lib/log4j-api-2.8.jar:/usr/local/apache-storm-1.0.6/lib/log4j-core-2.8.jar:/usr/local/apache-storm-1.0.6/lib/slf4j-api-1.7.21.jar:/usr/local/apache-storm-1.0.6/lib/kryo-3.0.3.jar:/usr/local/apache-storm-1.0.6/lib/storm-core-1.0.6.jar:/usr/local/apache-storm-1.0.6/lib/minlog-1.3.0.jar:/usr/local/apache-storm-1.0.6/lib/log4j-slf4j-impl-2.8.jar:/usr/local/apache-storm-1.0.6/lib/clojure-1.7.0.jar:target/storm-example-0.0.1-SNAPSHOT.jar:/usr/local/storm/conf:/usr/local/apache-storm-1.0.6/bin
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.io.tmpdir=/tmp
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.compiler=<NA>
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.name=Linux
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.arch=amd64
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.version=4.4.115-boot2docker
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.name=root
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.home=/root
3289 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.dir=/MP4_java
3299 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /tmp/f6a2fc0c-2011-4aac-910b-ef86e4458469/version-2 snapdir /tmp/f6a2fc0c-2011-4aac-910b-ef86e4458469/version-2
3318 [main] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:2000
3329 [main] INFO  o.a.s.zookeeper - Starting inprocess zookeeper at port 2000 and dir /tmp/f6a2fc0c-2011-4aac-910b-ef86e4458469
3666 [main] INFO  o.a.s.d.nimbus - Starting Nimbus with conf {"topology.builtin.metrics.bucket.size.secs" 60, "nimbus.childopts" "-Xmx1024m", "ui.filter.params" nil, "storm.cluster.mode" "local", "storm.messaging.netty.client_worker_threads" 1, "logviewer.max.per.worker.logs.size.mb" 2048, "supervisor.run.worker.as.user" false, "topology.max.task.parallelism" nil, "topology.priority" 29, "zmq.threads" 1, "storm.group.mapping.service" "org.apache.storm.security.auth.ShellBasedGroupsMapping", "transactional.zookeeper.root" "/transactional", "topology.sleep.spout.wait.strategy.time.ms" 1, "ui.pagination" 20, "scheduler.display.resource" false, "topology.max.replication.wait.time.sec" 60, "drpc.invocations.port" 3773, "supervisor.localizer.cache.target.size.mb" 10240, "topology.multilang.serializer" "org.apache.storm.multilang.JsonSerializer", "storm.messaging.netty.server_worker_threads" 1, "nimbus.blobstore.class" "org.apache.storm.blobstore.LocalFsBlobStore", "resource.aware.scheduler.eviction.strategy" "org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy", "topology.max.error.report.per.interval" 5, "storm.thrift.transport" "org.apache.storm.security.auth.SimpleTransportPlugin", "zmq.hwm" 0, "storm.group.mapping.service.params" nil, "worker.profiler.enabled" false, "storm.principal.tolocal" "org.apache.storm.security.auth.DefaultPrincipalToLocal", "supervisor.worker.shutdown.sleep.secs" 3, "pacemaker.host" "localhost", "storm.zookeeper.retry.times" 5, "ui.actions.enabled" true, "zmq.linger.millis" 0, "supervisor.enable" true, "topology.stats.sample.rate" 0.05, "storm.messaging.netty.min_wait_ms" 100, "worker.log.level.reset.poll.secs" 30, "storm.zookeeper.port" 2000, "supervisor.heartbeat.frequency.secs" 5, "topology.enable.message.timeouts" true, "supervisor.cpu.capacity" 400.0, "drpc.worker.threads" 64, "supervisor.blobstore.download.thread.count" 5, "task.backpressure.poll.secs" 30, "drpc.queue.size" 128, "topology.backpressure.enable" false, "supervisor.blobstore.class" "org.apache.storm.blobstore.NimbusBlobStore", "storm.blobstore.inputstream.buffer.size.bytes" 65536, "topology.shellbolt.max.pending" 100, "drpc.https.keystore.password" "", "nimbus.code.sync.freq.secs" 120, "logviewer.port" 8000, "topology.scheduler.strategy" "org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy", "topology.executor.send.buffer.size" 1024, "resource.aware.scheduler.priority.strategy" "org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy", "pacemaker.auth.method" "NONE", "storm.daemon.metrics.reporter.plugins" ["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], "topology.worker.logwriter.childopts" "-Xmx64m", "topology.spout.wait.strategy" "org.apache.storm.spout.SleepSpoutWaitStrategy", "ui.host" "0.0.0.0", "storm.nimbus.retry.interval.millis" 2000, "nimbus.inbox.jar.expiration.secs" 3600, "dev.zookeeper.path" "/tmp/dev-storm-zookeeper", "topology.acker.executors" nil, "topology.fall.back.on.java.serialization" true, "topology.eventlogger.executors" 0, "supervisor.localizer.cleanup.interval.ms" 600000, "storm.zookeeper.servers" ["localhost"], "nimbus.thrift.threads" 64, "logviewer.cleanup.age.mins" 10080, "topology.worker.childopts" nil, "topology.classpath" nil, "supervisor.monitor.frequency.secs" 3, "nimbus.credential.renewers.freq.secs" 600, "topology.skip.missing.kryo.registrations" true, "drpc.authorizer.acl.filename" "drpc-auth-acl.yaml", "pacemaker.kerberos.users" [], "storm.group.mapping.service.cache.duration.secs" 120, "blobstore.dir" "/tmp/44012f2a-9690-4934-81e2-fb298f5a5420", "topology.testing.always.try.serialize" false, "nimbus.monitor.freq.secs" 10, "storm.health.check.timeout.ms" 5000, "supervisor.supervisors" [], "topology.tasks" nil, "topology.bolts.outgoing.overflow.buffer.enable" false, "storm.messaging.netty.socket.backlog" 500, "topology.workers" 1, "pacemaker.base.threads" 10, "storm.local.dir" "/tmp/44012f2a-9690-4934-81e2-fb298f5a5420", "worker.childopts" "-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump", "storm.auth.simple-white-list.users" [], "topology.disruptor.batch.timeout.millis" 1, "topology.message.timeout.secs" 30, "topology.state.synchronization.timeout.secs" 60, "topology.tuple.serializer" "org.apache.storm.serialization.types.ListDelegateSerializer", "supervisor.supervisors.commands" [], "nimbus.blobstore.expiration.secs" 600, "logviewer.childopts" "-Xmx128m", "topology.environment" nil, "topology.debug" false, "topology.disruptor.batch.size" 100, "storm.disable.symlinks" false, "storm.messaging.netty.max_retries" 300, "ui.childopts" "-Xmx768m", "storm.network.topography.plugin" "org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping", "storm.zookeeper.session.timeout" 20000, "drpc.childopts" "-Xmx768m", "drpc.http.creds.plugin" "org.apache.storm.security.auth.DefaultHttpCredentialsPlugin", "storm.zookeeper.connection.timeout" 15000, "storm.zookeeper.auth.user" nil, "storm.meta.serialization.delegate" "org.apache.storm.serialization.GzipThriftSerializationDelegate", "topology.max.spout.pending" nil, "storm.codedistributor.class" "org.apache.storm.codedistributor.LocalFileSystemCodeDistributor", "nimbus.supervisor.timeout.secs" 60, "nimbus.task.timeout.secs" 30, "drpc.port" 3772, "pacemaker.max.threads" 50, "storm.zookeeper.retry.intervalceiling.millis" 30000, "nimbus.thrift.port" 6627, "storm.auth.simple-acl.admins" [], "topology.component.cpu.pcore.percent" 10.0, "supervisor.memory.capacity.mb" 3072.0, "storm.nimbus.retry.times" 5, "supervisor.worker.start.timeout.secs" 120, "storm.zookeeper.retry.interval" 1000, "logs.users" nil, "worker.profiler.command" "flight.bash", "transactional.zookeeper.port" nil, "drpc.max_buffer_size" 1048576, "pacemaker.thread.timeout" 10, "task.credentials.poll.secs" 30, "blobstore.superuser" "root", "drpc.https.keystore.type" "JKS", "topology.worker.receiver.thread.count" 1, "topology.state.checkpoint.interval.ms" 1000, "supervisor.slots.ports" [6700 6701 6702 6703], "topology.transfer.buffer.size" 1024, "storm.health.check.dir" "healthchecks", "topology.worker.shared.thread.pool.size" 4, "drpc.authorizer.acl.strict" false, "nimbus.file.copy.expiration.secs" 600, "worker.profiler.childopts" "-XX:+UnlockCommercialFeatures -XX:+FlightRecorder", "topology.executor.receive.buffer.size" 1024, "backpressure.disruptor.low.watermark" 0.4, "nimbus.task.launch.secs" 120, "storm.local.mode.zmq" false, "storm.messaging.netty.buffer_size" 5242880, "storm.cluster.state.store" "org.apache.storm.cluster_state.zookeeper_state_factory", "worker.heartbeat.frequency.secs" 1, "storm.log4j2.conf.dir" "log4j2", "ui.http.creds.plugin" "org.apache.storm.security.auth.DefaultHttpCredentialsPlugin", "storm.zookeeper.root" "/storm", "topology.tick.tuple.freq.secs" nil, "drpc.https.port" -1, "storm.workers.artifacts.dir" "workers-artifacts", "supervisor.blobstore.download.max_retries" 3, "task.refresh.poll.secs" 10, "storm.exhibitor.port" 8080, "task.heartbeat.frequency.secs" 3, "pacemaker.port" 6699, "storm.messaging.netty.max_wait_ms" 1000, "topology.component.resources.offheap.memory.mb" 0.0, "drpc.http.port" 3774, "topology.error.throttle.interval.secs" 10, "storm.messaging.transport" "org.apache.storm.messaging.netty.Context", "topology.disable.loadaware.messaging" false, "storm.messaging.netty.authentication" false, "topology.component.resources.onheap.memory.mb" 128.0, "topology.kryo.factory" "org.apache.storm.serialization.DefaultKryoFactory", "worker.gc.childopts" "", "nimbus.topology.validator" "org.apache.storm.nimbus.DefaultTopologyValidator", "nimbus.seeds" ["localhost"], "nimbus.queue.size" 100000, "nimbus.cleanup.inbox.freq.secs" 600, "storm.blobstore.replication.factor" 3, "worker.heap.memory.mb" 768, "logviewer.max.sum.worker.logs.size.mb" 4096, "pacemaker.childopts" "-Xmx1024m", "ui.users" nil, "transactional.zookeeper.servers" nil, "supervisor.worker.timeout.secs" 30, "storm.zookeeper.auth.password" nil, "storm.blobstore.acl.validation.enabled" false, "client.blobstore.class" "org.apache.storm.blobstore.NimbusBlobStore", "supervisor.childopts" "-Xmx256m", "topology.worker.max.heap.size.mb" 768.0, "ui.http.x-frame-options" "DENY", "backpressure.disruptor.high.watermark" 0.9, "ui.filter" nil, "ui.header.buffer.bytes" 4096, "topology.min.replication.count" 1, "topology.disruptor.wait.timeout.millis" 1000, "storm.nimbus.retry.intervalceiling.millis" 60000, "topology.trident.batch.emit.interval.millis" 50, "storm.auth.simple-acl.users" [], "drpc.invocations.threads" 64, "java.library.path" "/usr/local/lib:/opt/local/lib:/usr/lib", "ui.port" 8080, "storm.exhibitor.poll.uripath" "/exhibitor/v1/cluster/list", "storm.messaging.netty.transfer.batch.size" 262144, "logviewer.appender.name" "A1", "nimbus.thrift.max_buffer_size" 1048576, "storm.auth.simple-acl.users.commands" [], "drpc.request.timeout.secs" 600}
3668 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to e59e53cc954f
3755 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
3770 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
3771 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:host.name=e59e53cc954f
3771 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.version=1.8.0_162
3771 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.vendor=Oracle Corporation
3771 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
3771 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.class.path=/usr/local/apache-storm-1.0.6/lib/disruptor-3.3.2.jar:/usr/local/apache-storm-1.0.6/lib/storm-rename-hack-1.0.6.jar:/usr/local/apache-storm-1.0.6/lib/servlet-api-2.5.jar:/usr/local/apache-storm-1.0.6/lib/reflectasm-1.10.1.jar:/usr/local/apache-storm-1.0.6/lib/log4j-over-slf4j-1.6.6.jar:/usr/local/apache-storm-1.0.6/lib/objenesis-2.1.jar:/usr/local/apache-storm-1.0.6/lib/asm-5.0.3.jar:/usr/local/apache-storm-1.0.6/lib/log4j-api-2.8.jar:/usr/local/apache-storm-1.0.6/lib/log4j-core-2.8.jar:/usr/local/apache-storm-1.0.6/lib/slf4j-api-1.7.21.jar:/usr/local/apache-storm-1.0.6/lib/kryo-3.0.3.jar:/usr/local/apache-storm-1.0.6/lib/storm-core-1.0.6.jar:/usr/local/apache-storm-1.0.6/lib/minlog-1.3.0.jar:/usr/local/apache-storm-1.0.6/lib/log4j-slf4j-impl-2.8.jar:/usr/local/apache-storm-1.0.6/lib/clojure-1.7.0.jar:target/storm-example-0.0.1-SNAPSHOT.jar:/usr/local/storm/conf:/usr/local/apache-storm-1.0.6/bin
3771 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib
3772 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.io.tmpdir=/tmp
3772 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.compiler=<NA>
3772 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.name=Linux
3772 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.arch=amd64
3772 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.version=4.4.115-boot2docker
3772 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.name=root
3773 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.home=/root
3773 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.dir=/MP4_java
3773 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1e0a864d
3792 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
3804 [main] INFO  o.a.s.b.FileBlobStoreImpl - Creating new blob store based in /tmp/44012f2a-9690-4934-81e2-fb298f5a5420/blobs
3808 [main] INFO  o.a.s.d.nimbus - Using default scheduler
3809 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
3823 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@d5af0a5
3824 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
3839 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to e59e53cc954f
3855 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to e59e53cc954f
3870 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
3891 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6e6d4780
3899 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
3947 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
3949 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
3949 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36214
3952 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36216
3953 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
3953 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36214
3955 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.p.FileTxnLog - Creating new log file: log.1
3957 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36218
3957 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36216
3958 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36218
3972 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0000, negotiated timeout = 20000
3974 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
3975 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
3979 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0000 with negotiated timeout 20000 for client /127.0.0.1:36214
3982 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0001, negotiated timeout = 20000
3983 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
3983 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
3983 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0001 with negotiated timeout 20000 for client /127.0.0.1:36216
3984 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0002, negotiated timeout = 20000
3984 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
3985 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0002 with negotiated timeout 20000 for client /127.0.0.1:36218
3993 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
3995 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0000
3996 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36214 which had sessionid 0x162ee6230cd0000
3997 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
3997 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0000 closed
4001 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4010 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@43aeb5e0
4011 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4011 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36220
4012 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4012 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36220
4013 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0003 with negotiated timeout 20000 for client /127.0.0.1:36220
4015 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4017 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0003, negotiated timeout = 20000
4017 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@423c5404
4018 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4018 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36222
4018 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4019 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36222
4020 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0004 with negotiated timeout 20000 for client /127.0.0.1:36222
4020 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4022 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0004, negotiated timeout = 20000
4023 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4100 [main] INFO  o.a.s.zookeeper - Queued up for leader lock.
4123 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x162ee6230cd0001 type:create cxid:0x1 zxid:0x12 txntype:-1 reqpath:n/a Error Path:/storm/leader-lock Error:KeeperErrorCode = NoNode for /storm/leader-lock
4129 [Curator-Framework-0] WARN  o.a.s.s.o.a.c.u.ZKPaths - The version of ZooKeeper being used doesn't support Container nodes. CreateMode.PERSISTENT will be used instead.
4226 [main-EventThread] INFO  o.a.s.zookeeper - e59e53cc954f gained leadership, checking if it has all the topology code locally.
4240 [main] INFO  o.a.s.d.m.MetricsUtils - Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter
4241 [main] INFO  o.a.s.d.m.r.JmxPreparableReporter - Preparing...
4259 [main-EventThread] INFO  o.a.s.zookeeper - active-topology-ids [] local-topology-ids [] diff-topology []
4259 [main-EventThread] INFO  o.a.s.zookeeper - Accepting leadership, all active topology found localy.
4260 [main] INFO  o.a.s.d.common - Started statistics report plugin...
4280 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4281 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@5a8816cc
4294 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4294 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4294 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36224
4295 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36224
4296 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0005 with negotiated timeout 20000 for client /127.0.0.1:36224
4296 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0005, negotiated timeout = 20000
4297 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4297 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
4298 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
4299 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0005
4300 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0005 closed
4301 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
4301 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4307 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@11e355ca
4309 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36224 which had sessionid 0x162ee6230cd0005
4311 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4312 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4312 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4312 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36226
4312 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36226
4322 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@2ff7a73
4325 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4325 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36228
4325 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4326 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36228
4327 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0006 with negotiated timeout 20000 for client /127.0.0.1:36226
4327 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0006, negotiated timeout = 20000
4327 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4330 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0007 with negotiated timeout 20000 for client /127.0.0.1:36228
4330 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0007, negotiated timeout = 20000
4330 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4331 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
4332 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0007
4333 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0007 closed
4333 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4333 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
4335 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1e1b061
4343 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4344 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4343 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36228 which had sessionid 0x162ee6230cd0007
4344 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36230
4344 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36230
4346 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0008 with negotiated timeout 20000 for client /127.0.0.1:36230
4346 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0008, negotiated timeout = 20000
4346 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4377 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4380 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6e4599c0
4393 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4393 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4394 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36232
4394 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36232
4395 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0009 with negotiated timeout 20000 for client /127.0.0.1:36232
4396 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0009, negotiated timeout = 20000
4396 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4398 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
4399 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0009
4400 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0009 closed
4400 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36232 which had sessionid 0x162ee6230cd0009
4401 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
4401 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4410 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@69f0b0f4
4415 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4416 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36234
4418 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4418 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36234
4420 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd000a with negotiated timeout 20000 for client /127.0.0.1:36234
4420 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd000a, negotiated timeout = 20000
4420 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4427 [main] INFO  o.a.s.l.Localizer - Reconstruct localized resource: /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/supervisor/usercache
4427 [main] WARN  o.a.s.l.Localizer - No left over resources found for any user during reconstructing of local resources at: /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/supervisor/usercache
4451 [main] INFO  o.a.s.d.s.Supervisor - Starting Supervisor with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=[localhost], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/44012f2a-9690-4934-81e2-fb298f5a5420, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/be992f9f-4768-434f-b73c-d8bf70984cc8, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=root, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[1024, 1025, 1026], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=[localhost], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
4465 [main] WARN  o.a.s.d.s.Slot - SLOT e59e53cc954f:1024 Starting in state EMPTY - assignment null
4465 [main] WARN  o.a.s.d.s.Slot - SLOT e59e53cc954f:1025 Starting in state EMPTY - assignment null
4466 [main] WARN  o.a.s.d.s.Slot - SLOT e59e53cc954f:1026 Starting in state EMPTY - assignment null
4469 [main] INFO  o.a.s.l.AsyncLocalizer - Cleaning up unused topologies in /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/supervisor/stormdist
4483 [main] INFO  o.a.s.d.s.Supervisor - Starting supervisor with id 31913f07-602c-44fe-bffd-7ac3ef0e2a5f at host e59e53cc954f.
4484 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4484 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@3c854752
4493 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4493 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4493 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36236
4493 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36236
4495 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd000b with negotiated timeout 20000 for client /127.0.0.1:36236
4495 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd000b, negotiated timeout = 20000
4495 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4497 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
4497 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd000b
4499 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd000b closed
4499 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4500 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
4500 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36236 which had sessionid 0x162ee6230cd000b
4511 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@210d2a6c
4514 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4515 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36238
4517 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4517 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36238
4518 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd000c with negotiated timeout 20000 for client /127.0.0.1:36238
4519 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd000c, negotiated timeout = 20000
4519 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4526 [main] INFO  o.a.s.l.Localizer - Reconstruct localized resource: /tmp/047bde30-743d-428f-90ad-1e11153a6602/supervisor/usercache
4526 [main] WARN  o.a.s.l.Localizer - No left over resources found for any user during reconstructing of local resources at: /tmp/047bde30-743d-428f-90ad-1e11153a6602/supervisor/usercache
4535 [main] INFO  o.a.s.d.s.Supervisor - Starting Supervisor with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=[localhost], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/44012f2a-9690-4934-81e2-fb298f5a5420, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/047bde30-743d-428f-90ad-1e11153a6602, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=root, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[1027, 1028, 1029], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=[localhost], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
4543 [main] WARN  o.a.s.d.s.Slot - SLOT e59e53cc954f:1027 Starting in state EMPTY - assignment null
4543 [main] WARN  o.a.s.d.s.Slot - SLOT e59e53cc954f:1028 Starting in state EMPTY - assignment null
4543 [main] WARN  o.a.s.d.s.Slot - SLOT e59e53cc954f:1029 Starting in state EMPTY - assignment null
4543 [main] INFO  o.a.s.l.AsyncLocalizer - Cleaning up unused topologies in /tmp/047bde30-743d-428f-90ad-1e11153a6602/supervisor/stormdist
4551 [main] INFO  o.a.s.d.s.Supervisor - Starting supervisor with id c1c867a4-7ced-40bd-8ef3-b8f8c1a36267 at host e59e53cc954f.
4572 [main] WARN  o.a.s.u.Utils - STORM-VERSION new 1.0.6 old null
4582 [main] WARN  o.a.s.u.Utils - STORM-VERSION new 1.0.6 old 1.0.6
4647 [main] INFO  o.a.s.d.nimbus - Received topology submission for word-count (storm-1.0.6 JDK-1.8.0_162) with conf {"topology.max.task.parallelism" 3, "topology.submitter.principal" "", "topology.acker.executors" nil, "topology.eventlogger.executors" 0, "topology.debug" true, "storm.zookeeper.superACL" nil, "topology.users" (), "topology.submitter.user" "root", "topology.kryo.register" nil, "topology.kryo.decorators" (), "storm.id" "word-count-1-1524417836", "topology.name" "word-count"}
4657 [main] INFO  o.a.s.d.nimbus - uploadedJar 
4668 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4680 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@767599a7
4694 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4694 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4694 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36240
4695 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36240
4696 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd000d with negotiated timeout 20000 for client /127.0.0.1:36240
4696 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd000d, negotiated timeout = 20000
4697 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4698 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x162ee6230cd000d type:create cxid:0x2 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/storm/blobstoremaxkeysequencenumber Error:KeeperErrorCode = NoNode for /storm/blobstoremaxkeysequencenumber
4706 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
4708 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd000d
4709 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36240 which had sessionid 0x162ee6230cd000d
4709 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd000d closed
4710 [main] INFO  o.a.s.cluster - setup-path/blobstore/word-count-1-1524417836-stormconf.ser/e59e53cc954f:6627-1
4710 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
4729 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
4741 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@724aefc3
4745 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
4745 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
4746 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36242
4746 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36242
4749 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd000e with negotiated timeout 20000 for client /127.0.0.1:36242
4749 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd000e, negotiated timeout = 20000
4749 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
4753 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
4754 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd000e
4755 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd000e closed
4755 [main] INFO  o.a.s.cluster - setup-path/blobstore/word-count-1-1524417836-stormcode.ser/e59e53cc954f:6627-1
4756 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
4757 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36242 which had sessionid 0x162ee6230cd000e
4773 [main] INFO  o.a.s.d.nimbus - desired replication count 1 achieved, current-replication-count for conf key = 1, current-replication-count for code key = 1, current-replication-count for jar key = 1
4850 [main] INFO  o.a.s.d.nimbus - Activating word-count: word-count-1-1524417836
5114 [timer] INFO  o.a.s.s.EvenScheduler - Available slots: (["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1025] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1026] ["c1c867a4-7ced-40bd-8ef3-b8f8c1a36267" 1027] ["c1c867a4-7ced-40bd-8ef3-b8f8c1a36267" 1028] ["c1c867a4-7ced-40bd-8ef3-b8f8c1a36267" 1029])
5151 [timer] INFO  o.a.s.d.nimbus - Setting new assignment for topology id word-count-1-1524417836: #org.apache.storm.daemon.common.Assignment{:master-code-dir "/tmp/44012f2a-9690-4934-81e2-fb298f5a5420", :node->host {"31913f07-602c-44fe-bffd-7ac3ef0e2a5f" "e59e53cc954f"}, :executor->node+port {[8 8] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024], [7 7] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024], [6 6] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024], [5 5] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024], [4 4] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024], [3 3] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024], [2 2] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024], [1 1] ["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024]}, :executor->start-time-secs {[1 1] 1524417836, [2 2] 1524417836, [3 3] 1524417836, [4 4] 1524417836, [5 5] 1524417836, [6 6] 1524417836, [7 7] 1524417836, [8 8] 1524417836}, :worker->resources {["31913f07-602c-44fe-bffd-7ac3ef0e2a5f" 1024] [0.0 0.0 0.0]}, :owner "root"}
5501 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE EMPTY msInState: 1036 -> WAITING_FOR_BASIC_LOCALIZATION msInState: 0
5503 [Async Localizer] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
5503 [Async Localizer] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@62856d0c
5504 [Async Localizer] INFO  o.a.s.b.FileBlobStoreImpl - Creating new blob store based in /tmp/44012f2a-9690-4934-81e2-fb298f5a5420/blobs
5516 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
5516 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
5517 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36244
5517 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36244
5522 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd000f with negotiated timeout 20000 for client /127.0.0.1:36244
5522 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd000f, negotiated timeout = 20000
5523 [Async Localizer-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
5556 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
5557 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd000f
5558 [Async Localizer] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd000f closed
5562 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36244 which had sessionid 0x162ee6230cd000f
5565 [Async Localizer-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
5594 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_BASIC_LOCALIZATION msInState: 93 -> WAITING_FOR_BLOB_LOCALIZATION msInState: 0
5601 [SLOT_1024] INFO  o.a.s.d.s.Container - Setting up 31913f07-602c-44fe-bffd-7ac3ef0e2a5f:75c02806-4075-47d0-a14c-6ef1eb531f1f
5602 [SLOT_1024] INFO  o.a.s.d.s.Container - GET worker-user for 75c02806-4075-47d0-a14c-6ef1eb531f1f
5627 [SLOT_1024] INFO  o.a.s.d.s.Container - SET worker-user 75c02806-4075-47d0-a14c-6ef1eb531f1f root
5642 [SLOT_1024] INFO  o.a.s.d.worker - Launching worker for word-count-1-1524417836 on 31913f07-602c-44fe-bffd-7ac3ef0e2a5f:1024 with id 75c02806-4075-47d0-a14c-6ef1eb531f1f and conf {"topology.builtin.metrics.bucket.size.secs" 60, "nimbus.childopts" "-Xmx1024m", "ui.filter.params" nil, "storm.cluster.mode" "local", "storm.messaging.netty.client_worker_threads" 1, "logviewer.max.per.worker.logs.size.mb" 2048, "supervisor.run.worker.as.user" false, "topology.max.task.parallelism" nil, "topology.priority" 29, "zmq.threads" 1, "storm.group.mapping.service" "org.apache.storm.security.auth.ShellBasedGroupsMapping", "transactional.zookeeper.root" "/transactional", "topology.sleep.spout.wait.strategy.time.ms" 1, "ui.pagination" 20, "scheduler.display.resource" false, "topology.max.replication.wait.time.sec" 60, "drpc.invocations.port" 3773, "supervisor.localizer.cache.target.size.mb" 10240, "topology.multilang.serializer" "org.apache.storm.multilang.JsonSerializer", "storm.messaging.netty.server_worker_threads" 1, "nimbus.blobstore.class" "org.apache.storm.blobstore.LocalFsBlobStore", "resource.aware.scheduler.eviction.strategy" "org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy", "topology.max.error.report.per.interval" 5, "storm.thrift.transport" "org.apache.storm.security.auth.SimpleTransportPlugin", "zmq.hwm" 0, "storm.group.mapping.service.params" nil, "worker.profiler.enabled" false, "storm.principal.tolocal" "org.apache.storm.security.auth.DefaultPrincipalToLocal", "supervisor.worker.shutdown.sleep.secs" 3, "pacemaker.host" "localhost", "storm.zookeeper.retry.times" 5, "ui.actions.enabled" true, "zmq.linger.millis" 0, "supervisor.enable" true, "topology.stats.sample.rate" 0.05, "storm.messaging.netty.min_wait_ms" 100, "worker.log.level.reset.poll.secs" 30, "storm.zookeeper.port" 2000, "supervisor.heartbeat.frequency.secs" 5, "topology.enable.message.timeouts" true, "supervisor.cpu.capacity" 400.0, "drpc.worker.threads" 64, "supervisor.blobstore.download.thread.count" 5, "task.backpressure.poll.secs" 30, "drpc.queue.size" 128, "topology.backpressure.enable" false, "supervisor.blobstore.class" "org.apache.storm.blobstore.NimbusBlobStore", "storm.blobstore.inputstream.buffer.size.bytes" 65536, "topology.shellbolt.max.pending" 100, "drpc.https.keystore.password" "", "nimbus.code.sync.freq.secs" 120, "logviewer.port" 8000, "topology.scheduler.strategy" "org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy", "topology.executor.send.buffer.size" 1024, "resource.aware.scheduler.priority.strategy" "org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy", "pacemaker.auth.method" "NONE", "storm.daemon.metrics.reporter.plugins" ["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], "topology.worker.logwriter.childopts" "-Xmx64m", "topology.spout.wait.strategy" "org.apache.storm.spout.SleepSpoutWaitStrategy", "ui.host" "0.0.0.0", "storm.nimbus.retry.interval.millis" 2000, "nimbus.inbox.jar.expiration.secs" 3600, "dev.zookeeper.path" "/tmp/dev-storm-zookeeper", "topology.acker.executors" nil, "topology.fall.back.on.java.serialization" true, "topology.eventlogger.executors" 0, "supervisor.localizer.cleanup.interval.ms" 600000, "storm.zookeeper.servers" ["localhost"], "nimbus.thrift.threads" 64, "logviewer.cleanup.age.mins" 10080, "topology.worker.childopts" nil, "topology.classpath" nil, "supervisor.monitor.frequency.secs" 3, "nimbus.credential.renewers.freq.secs" 600, "topology.skip.missing.kryo.registrations" true, "drpc.authorizer.acl.filename" "drpc-auth-acl.yaml", "pacemaker.kerberos.users" [], "storm.group.mapping.service.cache.duration.secs" 120, "blobstore.dir" "/tmp/44012f2a-9690-4934-81e2-fb298f5a5420", "topology.testing.always.try.serialize" false, "nimbus.monitor.freq.secs" 10, "storm.health.check.timeout.ms" 5000, "supervisor.supervisors" [], "topology.tasks" nil, "topology.bolts.outgoing.overflow.buffer.enable" false, "storm.messaging.netty.socket.backlog" 500, "topology.workers" 1, "pacemaker.base.threads" 10, "storm.local.dir" "/tmp/be992f9f-4768-434f-b73c-d8bf70984cc8", "worker.childopts" "-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump", "storm.auth.simple-white-list.users" [], "topology.disruptor.batch.timeout.millis" 1, "topology.message.timeout.secs" 30, "topology.state.synchronization.timeout.secs" 60, "topology.tuple.serializer" "org.apache.storm.serialization.types.ListDelegateSerializer", "supervisor.supervisors.commands" [], "nimbus.blobstore.expiration.secs" 600, "logviewer.childopts" "-Xmx128m", "topology.environment" nil, "topology.debug" false, "topology.disruptor.batch.size" 100, "storm.disable.symlinks" false, "storm.messaging.netty.max_retries" 300, "ui.childopts" "-Xmx768m", "storm.network.topography.plugin" "org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping", "storm.zookeeper.session.timeout" 20000, "drpc.childopts" "-Xmx768m", "drpc.http.creds.plugin" "org.apache.storm.security.auth.DefaultHttpCredentialsPlugin", "storm.zookeeper.connection.timeout" 15000, "storm.zookeeper.auth.user" nil, "storm.meta.serialization.delegate" "org.apache.storm.serialization.GzipThriftSerializationDelegate", "topology.max.spout.pending" nil, "storm.codedistributor.class" "org.apache.storm.codedistributor.LocalFileSystemCodeDistributor", "nimbus.supervisor.timeout.secs" 60, "nimbus.task.timeout.secs" 30, "drpc.port" 3772, "pacemaker.max.threads" 50, "storm.zookeeper.retry.intervalceiling.millis" 30000, "nimbus.thrift.port" 6627, "storm.auth.simple-acl.admins" [], "topology.component.cpu.pcore.percent" 10.0, "supervisor.memory.capacity.mb" 3072.0, "storm.nimbus.retry.times" 5, "supervisor.worker.start.timeout.secs" 120, "storm.zookeeper.retry.interval" 1000, "logs.users" nil, "worker.profiler.command" "flight.bash", "transactional.zookeeper.port" nil, "drpc.max_buffer_size" 1048576, "pacemaker.thread.timeout" 10, "task.credentials.poll.secs" 30, "blobstore.superuser" "root", "drpc.https.keystore.type" "JKS", "topology.worker.receiver.thread.count" 1, "topology.state.checkpoint.interval.ms" 1000, "supervisor.slots.ports" (1024 1025 1026), "topology.transfer.buffer.size" 1024, "storm.health.check.dir" "healthchecks", "topology.worker.shared.thread.pool.size" 4, "drpc.authorizer.acl.strict" false, "nimbus.file.copy.expiration.secs" 600, "worker.profiler.childopts" "-XX:+UnlockCommercialFeatures -XX:+FlightRecorder", "topology.executor.receive.buffer.size" 1024, "backpressure.disruptor.low.watermark" 0.4, "nimbus.task.launch.secs" 120, "storm.local.mode.zmq" false, "storm.messaging.netty.buffer_size" 5242880, "storm.cluster.state.store" "org.apache.storm.cluster_state.zookeeper_state_factory", "worker.heartbeat.frequency.secs" 1, "storm.log4j2.conf.dir" "log4j2", "ui.http.creds.plugin" "org.apache.storm.security.auth.DefaultHttpCredentialsPlugin", "storm.zookeeper.root" "/storm", "topology.tick.tuple.freq.secs" nil, "drpc.https.port" -1, "storm.workers.artifacts.dir" "workers-artifacts", "supervisor.blobstore.download.max_retries" 3, "task.refresh.poll.secs" 10, "storm.exhibitor.port" 8080, "task.heartbeat.frequency.secs" 3, "pacemaker.port" 6699, "storm.messaging.netty.max_wait_ms" 1000, "topology.component.resources.offheap.memory.mb" 0.0, "drpc.http.port" 3774, "topology.error.throttle.interval.secs" 10, "storm.messaging.transport" "org.apache.storm.messaging.netty.Context", "topology.disable.loadaware.messaging" false, "storm.messaging.netty.authentication" false, "topology.component.resources.onheap.memory.mb" 128.0, "topology.kryo.factory" "org.apache.storm.serialization.DefaultKryoFactory", "worker.gc.childopts" "", "nimbus.topology.validator" "org.apache.storm.nimbus.DefaultTopologyValidator", "nimbus.seeds" ["localhost"], "nimbus.queue.size" 100000, "nimbus.cleanup.inbox.freq.secs" 600, "storm.blobstore.replication.factor" 3, "worker.heap.memory.mb" 768, "logviewer.max.sum.worker.logs.size.mb" 4096, "pacemaker.childopts" "-Xmx1024m", "ui.users" nil, "transactional.zookeeper.servers" nil, "supervisor.worker.timeout.secs" 30, "storm.zookeeper.auth.password" nil, "storm.blobstore.acl.validation.enabled" false, "client.blobstore.class" "org.apache.storm.blobstore.NimbusBlobStore", "supervisor.childopts" "-Xmx256m", "topology.worker.max.heap.size.mb" 768.0, "ui.http.x-frame-options" "DENY", "backpressure.disruptor.high.watermark" 0.9, "ui.filter" nil, "ui.header.buffer.bytes" 4096, "topology.min.replication.count" 1, "topology.disruptor.wait.timeout.millis" 1000, "storm.nimbus.retry.intervalceiling.millis" 60000, "topology.trident.batch.emit.interval.millis" 50, "storm.auth.simple-acl.users" [], "drpc.invocations.threads" 64, "java.library.path" "/usr/local/lib:/opt/local/lib:/usr/lib", "ui.port" 8080, "storm.exhibitor.poll.uripath" "/exhibitor/v1/cluster/list", "storm.messaging.netty.transfer.batch.size" 262144, "logviewer.appender.name" "A1", "nimbus.thrift.max_buffer_size" 1048576, "storm.auth.simple-acl.users.commands" [], "drpc.request.timeout.secs" 600}
5646 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
5646 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@55815857
5653 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
5654 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
5654 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36246
5654 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36246
5655 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0010 with negotiated timeout 20000 for client /127.0.0.1:36246
5655 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0010, negotiated timeout = 20000
5656 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
5656 [SLOT_1024-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
5656 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
5657 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0010
5658 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36246 which had sessionid 0x162ee6230cd0010
5658 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0010 closed
5658 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
5659 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
5660 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6bb0050d
5672 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
5672 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
5673 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:36248
5673 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:36248
5674 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x162ee6230cd0011 with negotiated timeout 20000 for client /127.0.0.1:36248
5674 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x162ee6230cd0011, negotiated timeout = 20000
5674 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
5680 [SLOT_1024] INFO  o.a.s.s.a.AuthUtils - Got AutoCreds []
5691 [SLOT_1024] INFO  o.a.s.d.worker - Reading Assignments.
5797 [SLOT_1024] INFO  o.a.s.d.worker - Registering IConnectionCallbacks for 31913f07-602c-44fe-bffd-7ac3ef0e2a5f:1024
5850 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor spout:[8 8]
5866 [SLOT_1024] INFO  o.a.s.d.task - Emitting: spout __system ["startup"]
5866 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks spout:[8 8]
6150 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor spout:[8 8]
6159 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor count:[2 2]
6162 [SLOT_1024] INFO  o.a.s.d.task - Emitting: count __system ["startup"]
6162 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks count:[2 2]
6172 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor count:[2 2]
6181 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor split:[7 7]
6182 [SLOT_1024] INFO  o.a.s.d.task - Emitting: split __system ["startup"]
6182 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks split:[7 7]
6192 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor split:[7 7]
6197 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor count:[3 3]
6198 [SLOT_1024] INFO  o.a.s.d.task - Emitting: count __system ["startup"]
6198 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks count:[3 3]
6203 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor count:[3 3]
6210 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor __acker:[1 1]
6211 [SLOT_1024] INFO  o.a.s.d.task - Emitting: __acker __system ["startup"]
6211 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks __acker:[1 1]
6218 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor __acker:[1 1]
6223 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor split:[6 6]
6224 [SLOT_1024] INFO  o.a.s.d.task - Emitting: split __system ["startup"]
6224 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks split:[6 6]
6231 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor split:[6 6]
6236 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor __system:[-1 -1]
6237 [SLOT_1024] INFO  o.a.s.d.task - Emitting: __system __system ["startup"]
6237 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks __system:[-1 -1]
6244 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor __system:[-1 -1]
6248 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor split:[5 5]
6248 [SLOT_1024] INFO  o.a.s.d.task - Emitting: split __system ["startup"]
6249 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks split:[5 5]
6254 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor split:[5 5]
6259 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor count:[4 4]
6260 [SLOT_1024] INFO  o.a.s.d.task - Emitting: count __system ["startup"]
6260 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks count:[4 4]
6268 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor count:[4 4]
6279 [SLOT_1024] INFO  o.a.s.d.worker - Started with log levels: {"" #object[org.apache.logging.log4j.Level 0x50c25a56 "INFO"], "org.apache.zookeeper" #object[org.apache.logging.log4j.Level 0x36080206 "WARN"]}
6294 [SLOT_1024] INFO  o.a.s.d.worker - Worker has topology config {"topology.builtin.metrics.bucket.size.secs" 60, "nimbus.childopts" "-Xmx1024m", "ui.filter.params" nil, "storm.cluster.mode" "local", "storm.messaging.netty.client_worker_threads" 1, "logviewer.max.per.worker.logs.size.mb" 2048, "supervisor.run.worker.as.user" false, "topology.max.task.parallelism" 3, "topology.priority" 29, "zmq.threads" 1, "storm.group.mapping.service" "org.apache.storm.security.auth.ShellBasedGroupsMapping", "transactional.zookeeper.root" "/transactional", "topology.sleep.spout.wait.strategy.time.ms" 1, "ui.pagination" 20, "scheduler.display.resource" false, "topology.max.replication.wait.time.sec" 60, "drpc.invocations.port" 3773, "supervisor.localizer.cache.target.size.mb" 10240, "topology.multilang.serializer" "org.apache.storm.multilang.JsonSerializer", "storm.messaging.netty.server_worker_threads" 1, "nimbus.blobstore.class" "org.apache.storm.blobstore.LocalFsBlobStore", "resource.aware.scheduler.eviction.strategy" "org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy", "topology.max.error.report.per.interval" 5, "storm.thrift.transport" "org.apache.storm.security.auth.SimpleTransportPlugin", "zmq.hwm" 0, "storm.group.mapping.service.params" nil, "worker.profiler.enabled" false, "storm.principal.tolocal" "org.apache.storm.security.auth.DefaultPrincipalToLocal", "supervisor.worker.shutdown.sleep.secs" 3, "pacemaker.host" "localhost", "storm.zookeeper.retry.times" 5, "ui.actions.enabled" true, "zmq.linger.millis" 0, "supervisor.enable" true, "topology.stats.sample.rate" 0.05, "storm.messaging.netty.min_wait_ms" 100, "worker.log.level.reset.poll.secs" 30, "storm.zookeeper.port" 2000, "supervisor.heartbeat.frequency.secs" 5, "topology.enable.message.timeouts" true, "supervisor.cpu.capacity" 400.0, "drpc.worker.threads" 64, "supervisor.blobstore.download.thread.count" 5, "task.backpressure.poll.secs" 30, "drpc.queue.size" 128, "topology.backpressure.enable" false, "supervisor.blobstore.class" "org.apache.storm.blobstore.NimbusBlobStore", "storm.blobstore.inputstream.buffer.size.bytes" 65536, "topology.shellbolt.max.pending" 100, "drpc.https.keystore.password" "", "nimbus.code.sync.freq.secs" 120, "logviewer.port" 8000, "topology.scheduler.strategy" "org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy", "topology.executor.send.buffer.size" 1024, "resource.aware.scheduler.priority.strategy" "org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy", "pacemaker.auth.method" "NONE", "storm.daemon.metrics.reporter.plugins" ["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], "topology.worker.logwriter.childopts" "-Xmx64m", "topology.spout.wait.strategy" "org.apache.storm.spout.SleepSpoutWaitStrategy", "ui.host" "0.0.0.0", "topology.submitter.principal" "", "storm.nimbus.retry.interval.millis" 2000, "nimbus.inbox.jar.expiration.secs" 3600, "dev.zookeeper.path" "/tmp/dev-storm-zookeeper", "topology.acker.executors" nil, "topology.fall.back.on.java.serialization" true, "topology.eventlogger.executors" 0, "supervisor.localizer.cleanup.interval.ms" 600000, "storm.zookeeper.servers" ["localhost"], "nimbus.thrift.threads" 64, "logviewer.cleanup.age.mins" 10080, "topology.worker.childopts" nil, "topology.classpath" nil, "supervisor.monitor.frequency.secs" 3, "nimbus.credential.renewers.freq.secs" 600, "topology.skip.missing.kryo.registrations" true, "drpc.authorizer.acl.filename" "drpc-auth-acl.yaml", "pacemaker.kerberos.users" [], "storm.group.mapping.service.cache.duration.secs" 120, "blobstore.dir" "/tmp/44012f2a-9690-4934-81e2-fb298f5a5420", "topology.testing.always.try.serialize" false, "nimbus.monitor.freq.secs" 10, "storm.health.check.timeout.ms" 5000, "supervisor.supervisors" [], "topology.tasks" nil, "topology.bolts.outgoing.overflow.buffer.enable" false, "storm.messaging.netty.socket.backlog" 500, "topology.workers" 1, "pacemaker.base.threads" 10, "storm.local.dir" "/tmp/44012f2a-9690-4934-81e2-fb298f5a5420", "worker.childopts" "-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump", "storm.auth.simple-white-list.users" [], "topology.disruptor.batch.timeout.millis" 1, "topology.message.timeout.secs" 30, "topology.state.synchronization.timeout.secs" 60, "topology.tuple.serializer" "org.apache.storm.serialization.types.ListDelegateSerializer", "supervisor.supervisors.commands" [], "nimbus.blobstore.expiration.secs" 600, "logviewer.childopts" "-Xmx128m", "topology.environment" nil, "topology.debug" true, "topology.disruptor.batch.size" 100, "storm.disable.symlinks" false, "storm.messaging.netty.max_retries" 300, "ui.childopts" "-Xmx768m", "storm.network.topography.plugin" "org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping", "storm.zookeeper.session.timeout" 20000, "drpc.childopts" "-Xmx768m", "drpc.http.creds.plugin" "org.apache.storm.security.auth.DefaultHttpCredentialsPlugin", "storm.zookeeper.connection.timeout" 15000, "storm.zookeeper.auth.user" nil, "storm.meta.serialization.delegate" "org.apache.storm.serialization.GzipThriftSerializationDelegate", "topology.max.spout.pending" nil, "storm.codedistributor.class" "org.apache.storm.codedistributor.LocalFileSystemCodeDistributor", "nimbus.supervisor.timeout.secs" 60, "nimbus.task.timeout.secs" 30, "storm.zookeeper.superACL" nil, "drpc.port" 3772, "pacemaker.max.threads" 50, "storm.zookeeper.retry.intervalceiling.millis" 30000, "nimbus.thrift.port" 6627, "storm.auth.simple-acl.admins" [], "topology.component.cpu.pcore.percent" 10.0, "supervisor.memory.capacity.mb" 3072.0, "storm.nimbus.retry.times" 5, "supervisor.worker.start.timeout.secs" 120, "storm.zookeeper.retry.interval" 1000, "logs.users" nil, "worker.profiler.command" "flight.bash", "transactional.zookeeper.port" nil, "drpc.max_buffer_size" 1048576, "pacemaker.thread.timeout" 10, "task.credentials.poll.secs" 30, "blobstore.superuser" "root", "drpc.https.keystore.type" "JKS", "topology.worker.receiver.thread.count" 1, "topology.state.checkpoint.interval.ms" 1000, "supervisor.slots.ports" [6700 6701 6702 6703], "topology.transfer.buffer.size" 1024, "storm.health.check.dir" "healthchecks", "topology.worker.shared.thread.pool.size" 4, "drpc.authorizer.acl.strict" false, "nimbus.file.copy.expiration.secs" 600, "worker.profiler.childopts" "-XX:+UnlockCommercialFeatures -XX:+FlightRecorder", "topology.executor.receive.buffer.size" 1024, "backpressure.disruptor.low.watermark" 0.4, "topology.users" [], "nimbus.task.launch.secs" 120, "storm.local.mode.zmq" false, "storm.messaging.netty.buffer_size" 5242880, "storm.cluster.state.store" "org.apache.storm.cluster_state.zookeeper_state_factory", "worker.heartbeat.frequency.secs" 1, "storm.log4j2.conf.dir" "log4j2", "ui.http.creds.plugin" "org.apache.storm.security.auth.DefaultHttpCredentialsPlugin", "storm.zookeeper.root" "/storm", "topology.submitter.user" "root", "topology.tick.tuple.freq.secs" nil, "drpc.https.port" -1, "storm.workers.artifacts.dir" "workers-artifacts", "supervisor.blobstore.download.max_retries" 3, "task.refresh.poll.secs" 10, "storm.exhibitor.port" 8080, "task.heartbeat.frequency.secs" 3, "pacemaker.port" 6699, "storm.messaging.netty.max_wait_ms" 1000, "topology.component.resources.offheap.memory.mb" 0.0, "drpc.http.port" 3774, "topology.error.throttle.interval.secs" 10, "storm.messaging.transport" "org.apache.storm.messaging.netty.Context", "topology.disable.loadaware.messaging" false, "storm.messaging.netty.authentication" false, "topology.component.resources.onheap.memory.mb" 128.0, "topology.kryo.factory" "org.apache.storm.serialization.DefaultKryoFactory", "topology.kryo.register" nil, "worker.gc.childopts" "", "nimbus.topology.validator" "org.apache.storm.nimbus.DefaultTopologyValidator", "nimbus.seeds" ["localhost"], "nimbus.queue.size" 100000, "nimbus.cleanup.inbox.freq.secs" 600, "storm.blobstore.replication.factor" 3, "worker.heap.memory.mb" 768, "logviewer.max.sum.worker.logs.size.mb" 4096, "pacemaker.childopts" "-Xmx1024m", "ui.users" nil, "transactional.zookeeper.servers" nil, "supervisor.worker.timeout.secs" 30, "storm.zookeeper.auth.password" nil, "storm.blobstore.acl.validation.enabled" false, "client.blobstore.class" "org.apache.storm.blobstore.NimbusBlobStore", "supervisor.childopts" "-Xmx256m", "topology.worker.max.heap.size.mb" 768.0, "ui.http.x-frame-options" "DENY", "backpressure.disruptor.high.watermark" 0.9, "ui.filter" nil, "ui.header.buffer.bytes" 4096, "topology.min.replication.count" 1, "topology.disruptor.wait.timeout.millis" 1000, "storm.nimbus.retry.intervalceiling.millis" 60000, "topology.trident.batch.emit.interval.millis" 50, "storm.auth.simple-acl.users" [], "drpc.invocations.threads" 64, "java.library.path" "/usr/local/lib:/opt/local/lib:/usr/lib", "ui.port" 8080, "topology.kryo.decorators" [], "storm.id" "word-count-1-1524417836", "topology.name" "word-count", "storm.exhibitor.poll.uripath" "/exhibitor/v1/cluster/list", "storm.messaging.netty.transfer.batch.size" 262144, "logviewer.appender.name" "A1", "nimbus.thrift.max_buffer_size" 1048576, "storm.auth.simple-acl.users.commands" [], "drpc.request.timeout.secs" 600}
6294 [SLOT_1024] INFO  o.a.s.d.worker - Worker 75c02806-4075-47d0-a14c-6ef1eb531f1f for storm word-count-1-1524417836 on 31913f07-602c-44fe-bffd-7ac3ef0e2a5f:1024 has finished loading
6294 [SLOT_1024] INFO  o.a.s.d.s.Container - SET worker-user 75c02806-4075-47d0-a14c-6ef1eb531f1f root
6295 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_BLOB_LOCALIZATION msInState: 701 -> WAITING_FOR_WORKER_START msInState: 0 topo:word-count-1-1524417836 worker:75c02806-4075-47d0-a14c-6ef1eb531f1f
6295 [SLOT_1024] INFO  o.a.s.d.s.Slot - SLOT 1024: Changing current assignment from null to LocalAssignment(topology_id:word-count-1-1524417836, executors:[ExecutorInfo(task_start:8, task_end:8), ExecutorInfo(task_start:7, task_end:7), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:5, task_end:5), ExecutorInfo(task_start:4, task_end:4), ExecutorInfo(task_start:3, task_end:3), ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:1, task_end:1)], resources:WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), owner:root)
6302 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_WORKER_START msInState: 7 topo:word-count-1-1524417836 worker:75c02806-4075-47d0-a14c-6ef1eb531f1f -> RUNNING msInState: 0 topo:word-count-1-1524417836 worker:75c02806-4075-47d0-a14c-6ef1eb531f1f
6752 [refresh-active-timer] INFO  o.a.s.d.worker - All connections are ready for worker 31913f07-602c-44fe-bffd-7ac3ef0e2a5f:1024 with id 75c02806-4075-47d0-a14c-6ef1eb531f1f
6766 [Thread-18-spout-executor[8 8]] INFO  o.a.s.d.executor - Opening spout spout:(8)
6766 [Thread-32-split-executor[5 5]] INFO  o.a.s.d.executor - Preparing bolt split:(5)
6779 [Thread-18-spout-executor[8 8]] INFO  o.a.s.d.executor - Opened spout spout:(8)
6780 [Thread-34-count-executor[4 4]] INFO  o.a.s.d.executor - Preparing bolt count:(4)
6782 [Thread-34-count-executor[4 4]] INFO  o.a.s.d.executor - Prepared bolt count:(4)
6783 [Thread-32-split-executor[5 5]] INFO  o.a.s.d.executor - Prepared bolt split:(5)
6783 [Thread-20-count-executor[2 2]] INFO  o.a.s.d.executor - Preparing bolt count:(2)
6783 [Thread-20-count-executor[2 2]] INFO  o.a.s.d.executor - Prepared bolt count:(2)
6791 [Thread-18-spout-executor[8 8]] INFO  o.a.s.d.executor - Activating spout spout:(8)
6811 [Thread-22-split-executor[7 7]] INFO  o.a.s.d.executor - Preparing bolt split:(7)
6813 [Thread-22-split-executor[7 7]] INFO  o.a.s.d.executor - Prepared bolt split:(7)
6821 [Thread-24-count-executor[3 3]] INFO  o.a.s.d.executor - Preparing bolt count:(3)
6821 [Thread-24-count-executor[3 3]] INFO  o.a.s.d.executor - Prepared bolt count:(3)
6834 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Preparing bolt __acker:(1)
6836 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Prepared bolt __acker:(1)
6845 [Thread-28-split-executor[6 6]] INFO  o.a.s.d.executor - Preparing bolt split:(6)
6845 [Thread-28-split-executor[6 6]] INFO  o.a.s.d.executor - Prepared bolt split:(6)
6864 [Thread-30-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Preparing bolt __system:(-1)
6868 [Thread-30-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Prepared bolt __system:(-1)
36782 [Thread-18-spout-executor[8 8]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __tick, id: {}, [30]
36839 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __tick, id: {}, [30]
36840 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Execute done TUPLE source: __system:-1, stream: __tick, id: {}, [30] TASK: 1 DELTA: -1
66792 [Thread-20-count-executor[2 2]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66794 [Thread-32-split-executor[5 5]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66796 [Thread-34-count-executor[4 4]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66797 [Thread-32-split-executor[5 5]] INFO  o.a.s.d.task - Emitting: split __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x4ca5c8f "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@4ca5c8f"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x4a394015 "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x3584fd10 "[__process-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x329dbf38 "[__receive = {arrival_rate_secs=0.11012003083360863, overflow=0, read_pos=-1, write_pos=0, sojourn_time_ms=9081.0, capacity=1024, population=1}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x64e5a3c0 "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x645c6ea1 "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x76a27347 "[__execute-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x299976d4 "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x60ab3b84 "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x67057856 "[__execute-count = {}]"]]]
66798 [Thread-34-count-executor[4 4]] INFO  o.a.s.d.task - Emitting: count __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x742f62b3 "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@742f62b3"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x312de252 "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x77f26ca5 "[__process-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x569192 "[__receive = {arrival_rate_secs=0.11012003083360863, overflow=0, read_pos=-1, write_pos=0, sojourn_time_ms=9081.0, capacity=1024, population=1}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0xf6341d1 "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x51021d1d "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x3571d4dc "[__execute-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x19f09e1 "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x1467adca "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x554ca0ae "[__execute-count = {}]"]]]
66799 [Thread-20-count-executor[2 2]] INFO  o.a.s.d.task - Emitting: count __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x2b245bf7 "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@2b245bf7"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x5e237d77 "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x53eb0b31 "[__process-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0xf298c41 "[__receive = {arrival_rate_secs=0.11008366358432409, overflow=0, read_pos=-1, write_pos=0, sojourn_time_ms=9084.0, capacity=1024, population=1}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6db85b0 "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x43d698d9 "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x48efa111 "[__execute-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0xb6777c9 "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x51cb8510 "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x262ccfa0 "[__execute-count = {}]"]]]
66801 [Thread-18-spout-executor[8 8]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __tick, id: {}, [30]
66801 [Thread-18-spout-executor[8 8]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66803 [Thread-18-spout-executor[8 8]] INFO  o.a.s.d.task - Emitting: spout __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x13b1600f "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@13b1600f"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x66fd2537 "[__complete-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x192b5210 "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x7aaad16f "[__receive = {arrival_rate_secs=0.21997360316761988, overflow=0, read_pos=0, write_pos=2, sojourn_time_ms=9092.0, capacity=1024, population=2}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6283672d "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6d5822d7 "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x2ea046be "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x22dcbac "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x7bee6ecb "[__skipped-max-spout = 0]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x570ca5fb "[__skipped-inactive = 0]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x7bb58c12 "[__skipped-throttle = 0]"]]]
66815 [Thread-22-split-executor[7 7]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66816 [Thread-22-split-executor[7 7]] INFO  o.a.s.d.task - Emitting: split __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x4b8b2a43 "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@4b8b2a43"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x454cdd42 "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x41734133 "[__process-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x471d779 "[__receive = {arrival_rate_secs=0.10987803538072739, overflow=0, read_pos=-1, write_pos=0, sojourn_time_ms=9101.0, capacity=1024, population=1}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x16ba2c86 "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x35bf55de "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6e9ef083 "[__execute-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x645e2836 "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x23c7e627 "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6c195624 "[__execute-count = {}]"]]]
66823 [Thread-24-count-executor[3 3]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66831 [Thread-24-count-executor[3 3]] INFO  o.a.s.d.task - Emitting: count __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x3cbf35ff "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@3cbf35ff"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x3278cc18 "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x36475e8f "[__process-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x7345c623 "[__receive = {arrival_rate_secs=0.10976948408342481, overflow=0, read_pos=-1, write_pos=0, sojourn_time_ms=9110.0, capacity=1024, population=1}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x36900579 "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x42fc17bf "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x4ec38a49 "[__execute-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x136a396c "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x25674db5 "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x784f749 "[__execute-count = {}]"]]]
66837 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66839 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.task - Emitting: __acker __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x6218b0a4 "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@6218b0a4"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x271a2283 "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x494a73cf "[__process-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x16f7e0b6 "[__receive = {arrival_rate_secs=0.10961306587745259, overflow=0, read_pos=0, write_pos=1, sojourn_time_ms=9123.0, capacity=1024, population=1}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x314def5c "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x4735ddcc "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x5d7b0aee "[__execute-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x7420b3a7 "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x2a498570 "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x437be648 "[__execute-count = {}]"]]]
66843 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __tick, id: {}, [30]
66844 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Execute done TUPLE source: __system:-1, stream: __tick, id: {}, [30] TASK: 1 DELTA: -1
66846 [Thread-28-split-executor[6 6]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66847 [Thread-28-split-executor[6 6]] INFO  o.a.s.d.task - Emitting: split __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x67c1a3b3 "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@67c1a3b3"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6906413b "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6d39c8c3 "[__process-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x283b4b00 "[__receive = {arrival_rate_secs=0.10951702989814917, overflow=0, read_pos=-1, write_pos=0, sojourn_time_ms=9131.0, capacity=1024, population=1}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x420da98f "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x1959276c "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x3a859b54 "[__execute-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x4814b44f "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x67fa3d13 "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x37c814c7 "[__execute-count = {}]"]]]
66871 [Thread-30-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __metrics_tick, id: {}, [60]
66876 [Thread-30-__system-executor[-1 -1]] INFO  o.a.s.d.task - Emitting: __system __metrics [#object[org.apache.storm.metric.api.IMetricsConsumer$TaskInfo 0x79110754 "org.apache.storm.metric.api.IMetricsConsumer$TaskInfo@79110754"] [#object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6f5fb514 "[uptimeSecs = 66.898]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x264aea1b "[__ack-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x5855b77a "[__transfer-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x290f2083 "[newWorkerEvent = 1]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x3bead7a3 "[__send-iconnection = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x4a81e8f7 "[__fail-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x3f1a78ba "[startTimeSecs = 1.524417831879E9]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x6fc15ce2 "[__emit-count = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x27bc976 "[memory/nonHeap = {unusedBytes=1271416, virtualFreeBytes=-58366345, initBytes=2555904, committedBytes=59637760, maxBytes=-1, usedBytes=58366344}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x47784f9e "[__process-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x2bcb3063 "[__receive = {arrival_rate_secs=0.1091703056768559, overflow=0, read_pos=-1, write_pos=0, sojourn_time_ms=9160.0, capacity=1024, population=1}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x4e885fb4 "[__transfer = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x12e41f6a "[__execute-latency = {}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x1765a617 "[__sendqueue = {arrival_rate_secs=0.0, overflow=0, read_pos=-1, write_pos=-1, sojourn_time_ms=0.0, capacity=1024, population=0}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x655fd4b0 "[memory/heap = {unusedBytes=42386920, virtualFreeBytes=980927976, initBytes=65011712, committedBytes=62980096, maxBytes=1001521152, usedBytes=20593176}]"] #object[org.apache.storm.metric.api.IMetricsConsumer$DataPoint 0x69264250 "[__execute-count = {}]"]]]
96788 [Thread-18-spout-executor[8 8]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __tick, id: {}, [30]
96841 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Processing received message FOR -2 TUPLE: source: __system:-1, stream: __tick, id: {}, [30]
96842 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.d.executor - Execute done TUPLE source: __system:-1, stream: __tick, id: {}, [30] TASK: 1 DELTA: -1
124945 [main] INFO  o.a.s.d.nimbus - Shutting down master
124950 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
124956 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0003
124964 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36220 which had sessionid 0x162ee6230cd0003
124965 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
124965 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0003 closed
124965 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
124970 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0004
124971 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36222 which had sessionid 0x162ee6230cd0004
124972 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
124972 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0004 closed
124976 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
124980 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0002
124981 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36218 which had sessionid 0x162ee6230cd0002
124983 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
124983 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0002 closed
124983 [main] INFO  o.a.s.zookeeper - closing zookeeper connection of leader elector.
124983 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
124985 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0001
124987 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36216 which had sessionid 0x162ee6230cd0001
124989 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
124990 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0001 closed
124990 [main] INFO  o.a.s.d.nimbus - Shut down master
124992 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
124996 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0006
124998 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36226 which had sessionid 0x162ee6230cd0006
125001 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
125002 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0006 closed
125002 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
125002 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0008
125004 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36230 which had sessionid 0x162ee6230cd0008
125004 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
125004 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0008 closed
125005 [main] INFO  o.a.s.d.s.ReadClusterState - Setting Thread[SLOT_1024,5,main] assignment to null
125005 [main] INFO  o.a.s.d.s.ReadClusterState - Setting Thread[SLOT_1025,5,main] assignment to null
125005 [main] INFO  o.a.s.d.s.ReadClusterState - Setting Thread[SLOT_1026,5,main] assignment to null
125005 [main] INFO  o.a.s.d.s.ReadClusterState - Waiting for Thread[SLOT_1024,5,main] to be EMPTY, currently RUNNING
126006 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126107 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126207 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126308 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126359 [SLOT_1024] WARN  o.a.s.d.s.Slot - SLOT 1024: Assignment Changed from LocalAssignment(topology_id:word-count-1-1524417836, executors:[ExecutorInfo(task_start:8, task_end:8), ExecutorInfo(task_start:7, task_end:7), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:5, task_end:5), ExecutorInfo(task_start:4, task_end:4), ExecutorInfo(task_start:3, task_end:3), ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:1, task_end:1)], resources:WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), owner:root) to null
126359 [SLOT_1024] INFO  o.a.s.ProcessSimulator - Begin killing process 75c02806-4075-47d0-a14c-6ef1eb531f1f
126359 [SLOT_1024] INFO  o.a.s.d.worker - Shutting down worker word-count-1-1524417836 31913f07-602c-44fe-bffd-7ac3ef0e2a5f 1024
126359 [SLOT_1024] INFO  o.a.s.d.worker - Terminating messaging context
126359 [SLOT_1024] INFO  o.a.s.d.worker - Shutting down executors
126360 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor spout:[8 8]
126361 [Thread-17-disruptor-executor[8 8]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126361 [Thread-18-spout-executor[8 8]] INFO  o.a.s.util - Async loop interrupted!
126363 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor spout:[8 8]
126363 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor count:[2 2]
126363 [Thread-20-count-executor[2 2]] INFO  o.a.s.util - Async loop interrupted!
126364 [Thread-19-disruptor-executor[2 2]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126364 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor count:[2 2]
126365 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor split:[7 7]
126365 [Thread-22-split-executor[7 7]] INFO  o.a.s.util - Async loop interrupted!
126365 [Thread-21-disruptor-executor[7 7]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126366 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor split:[7 7]
126369 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor count:[3 3]
126370 [Thread-24-count-executor[3 3]] INFO  o.a.s.util - Async loop interrupted!
126370 [Thread-23-disruptor-executor[3 3]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126374 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor count:[3 3]
126374 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor __acker:[1 1]
126374 [Thread-26-__acker-executor[1 1]] INFO  o.a.s.util - Async loop interrupted!
126375 [Thread-25-disruptor-executor[1 1]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126377 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor __acker:[1 1]
126377 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor split:[6 6]
126377 [Thread-28-split-executor[6 6]] INFO  o.a.s.util - Async loop interrupted!
126377 [Thread-27-disruptor-executor[6 6]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126378 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor split:[6 6]
126378 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor __system:[-1 -1]
126378 [Thread-30-__system-executor[-1 -1]] INFO  o.a.s.util - Async loop interrupted!
126378 [Thread-29-disruptor-executor[-1 -1]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126378 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor __system:[-1 -1]
126380 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor split:[5 5]
126380 [Thread-32-split-executor[5 5]] INFO  o.a.s.util - Async loop interrupted!
126380 [Thread-31-disruptor-executor[5 5]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126382 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor split:[5 5]
126383 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor count:[4 4]
126383 [Thread-34-count-executor[4 4]] INFO  o.a.s.util - Async loop interrupted!
126383 [Thread-33-disruptor-executor[4 4]-send-queue] INFO  o.a.s.util - Async loop interrupted!
126384 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor count:[4 4]
126385 [SLOT_1024] INFO  o.a.s.d.worker - Shut down executors
126385 [SLOT_1024] INFO  o.a.s.d.worker - Shutting down transfer thread
126386 [Thread-35-disruptor-worker-transfer-queue] INFO  o.a.s.util - Async loop interrupted!
126386 [SLOT_1024] INFO  o.a.s.d.worker - Shut down transfer thread
126386 [SLOT_1024] INFO  o.a.s.d.worker - Shut down backpressure thread
126391 [SLOT_1024] INFO  o.a.s.d.worker - Shutting down default resources
126391 [SLOT_1024] INFO  o.a.s.d.worker - Shut down default resources
126391 [SLOT_1024] INFO  o.a.s.d.worker - Trigger any worker shutdown hooks
126403 [SLOT_1024] INFO  o.a.s.d.worker - Disconnecting from storm cluster state context
126403 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
126404 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd0011
126405 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36248 which had sessionid 0x162ee6230cd0011
126405 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
126405 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd0011 closed
126405 [SLOT_1024] INFO  o.a.s.d.worker - Shut down worker word-count-1-1524417836 31913f07-602c-44fe-bffd-7ac3ef0e2a5f 1024
126405 [SLOT_1024] INFO  o.a.s.ProcessSimulator - Successfully killed process 75c02806-4075-47d0-a14c-6ef1eb531f1f
126405 [SLOT_1024] INFO  o.a.s.d.s.Container - Killing 31913f07-602c-44fe-bffd-7ac3ef0e2a5f:75c02806-4075-47d0-a14c-6ef1eb531f1f
126408 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126508 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126609 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126709 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126809 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
126910 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127010 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127110 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127211 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127311 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127412 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127512 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127613 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127713 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127813 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
127914 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128014 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128114 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128215 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128316 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128416 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128516 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128617 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128717 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128818 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
128922 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
129022 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
129123 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
129223 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
129323 [main] WARN  o.a.s.d.s.ReadClusterState - It has taken 1000ms so far and Thread[SLOT_1024,5,main] is still not shut down.
129406 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE RUNNING msInState: 123104 topo:word-count-1-1524417836 worker:75c02806-4075-47d0-a14c-6ef1eb531f1f -> KILL msInState: 0 topo:word-count-1-1524417836 worker:75c02806-4075-47d0-a14c-6ef1eb531f1f
129406 [SLOT_1024] INFO  o.a.s.d.s.Container - GET worker-user for 75c02806-4075-47d0-a14c-6ef1eb531f1f
129407 [SLOT_1024] WARN  o.a.s.d.s.Slot - SLOT 1024 all processes are dead...
129407 [SLOT_1024] INFO  o.a.s.d.s.Container - Cleaning up 31913f07-602c-44fe-bffd-7ac3ef0e2a5f:75c02806-4075-47d0-a14c-6ef1eb531f1f
129407 [SLOT_1024] INFO  o.a.s.d.s.Container - GET worker-user for 75c02806-4075-47d0-a14c-6ef1eb531f1f
129407 [SLOT_1024] INFO  o.a.s.d.s.AdvancedFSOps - Deleting path /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/workers/75c02806-4075-47d0-a14c-6ef1eb531f1f/heartbeats
129414 [SLOT_1024] INFO  o.a.s.d.s.AdvancedFSOps - Deleting path /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/workers/75c02806-4075-47d0-a14c-6ef1eb531f1f/pids
129415 [SLOT_1024] INFO  o.a.s.d.s.AdvancedFSOps - Deleting path /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/workers/75c02806-4075-47d0-a14c-6ef1eb531f1f/tmp
129415 [SLOT_1024] INFO  o.a.s.d.s.AdvancedFSOps - Deleting path /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/workers/75c02806-4075-47d0-a14c-6ef1eb531f1f
129415 [SLOT_1024] INFO  o.a.s.d.s.Container - REMOVE worker-user 75c02806-4075-47d0-a14c-6ef1eb531f1f
129415 [SLOT_1024] INFO  o.a.s.d.s.AdvancedFSOps - Deleting path /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/workers-users/75c02806-4075-47d0-a14c-6ef1eb531f1f
129415 [SLOT_1024] INFO  o.a.s.l.AsyncLocalizer - Released blob reference word-count-1-1524417836 1024 Cleaning up BLOB references...
129416 [SLOT_1024] INFO  o.a.s.l.AsyncLocalizer - Released blob reference word-count-1-1524417836 1024 Cleaning up basic files...
129416 [SLOT_1024] INFO  o.a.s.d.s.AdvancedFSOps - Deleting path /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8/supervisor/stormdist/word-count-1-1524417836
129416 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE KILL msInState: 10 topo:word-count-1-1524417836 worker:null -> EMPTY msInState: 0
129416 [SLOT_1024] INFO  o.a.s.d.s.Slot - SLOT 1024: Changing current assignment from LocalAssignment(topology_id:word-count-1-1524417836, executors:[ExecutorInfo(task_start:8, task_end:8), ExecutorInfo(task_start:7, task_end:7), ExecutorInfo(task_start:6, task_end:6), ExecutorInfo(task_start:5, task_end:5), ExecutorInfo(task_start:4, task_end:4), ExecutorInfo(task_start:3, task_end:3), ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:1, task_end:1)], resources:WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), owner:root) to null
129424 [main] INFO  o.a.s.d.s.ReadClusterState - Waiting for Thread[SLOT_1025,5,main] to be EMPTY, currently EMPTY
129424 [main] INFO  o.a.s.d.s.ReadClusterState - Waiting for Thread[SLOT_1026,5,main] to be EMPTY, currently EMPTY
129424 [main] INFO  o.a.s.d.s.Supervisor - Shutting down supervisor 31913f07-602c-44fe-bffd-7ac3ef0e2a5f
129425 [Thread-10] WARN  o.a.s.d.s.ReadClusterState - null : retrying 1 of 3
129429 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
129429 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd000a
129430 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36234 which had sessionid 0x162ee6230cd000a
129430 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
129430 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd000a closed
129431 [main] INFO  o.a.s.d.s.ReadClusterState - Setting Thread[SLOT_1027,5,main] assignment to null
129431 [main] INFO  o.a.s.d.s.ReadClusterState - Setting Thread[SLOT_1028,5,main] assignment to null
129431 [main] INFO  o.a.s.d.s.ReadClusterState - Setting Thread[SLOT_1029,5,main] assignment to null
129431 [main] INFO  o.a.s.d.s.ReadClusterState - Waiting for Thread[SLOT_1027,5,main] to be EMPTY, currently EMPTY
129431 [main] INFO  o.a.s.d.s.ReadClusterState - Waiting for Thread[SLOT_1028,5,main] to be EMPTY, currently EMPTY
129431 [main] INFO  o.a.s.d.s.ReadClusterState - Waiting for Thread[SLOT_1029,5,main] to be EMPTY, currently EMPTY
129431 [main] INFO  o.a.s.d.s.Supervisor - Shutting down supervisor c1c867a4-7ced-40bd-8ef3-b8f8c1a36267
129431 [Thread-14] INFO  o.a.s.e.EventManagerImp - Event manager interrupted
129432 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
129433 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x162ee6230cd000c
129434 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:36238 which had sessionid 0x162ee6230cd000c
129434 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
129434 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x162ee6230cd000c closed
129435 [main] INFO  o.a.s.testing - Shutting down in process zookeeper
129435 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
129435 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - shutting down
129435 [main] INFO  o.a.s.s.o.a.z.s.SessionTrackerImpl - Shutting down
129435 [main] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Shutting down
129435 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - PrepRequestProcessor exited loop!
129435 [main] INFO  o.a.s.s.o.a.z.s.SyncRequestProcessor - Shutting down
129435 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.SyncRequestProcessor - SyncRequestProcessor exited!
129435 [main] INFO  o.a.s.s.o.a.z.s.FinalRequestProcessor - shutdown of request processor complete
129436 [main] INFO  o.a.s.testing - Done shutting down in process zookeeper
129436 [main] INFO  o.a.s.testing - Deleting temporary path /tmp/44012f2a-9690-4934-81e2-fb298f5a5420
129446 [main] INFO  o.a.s.testing - Deleting temporary path /tmp/f6a2fc0c-2011-4aac-910b-ef86e4458469
129447 [main] INFO  o.a.s.testing - Deleting temporary path /tmp/be992f9f-4768-434f-b73c-d8bf70984cc8
129448 [main] INFO  o.a.s.testing - Deleting temporary path /tmp/047bde30-743d-428f-90ad-1e11153a6602
130121 [SessionTracker] INFO  o.a.s.s.o.a.z.s.SessionTrackerImpl - SessionTrackerImpl exited loop!
